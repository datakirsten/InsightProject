{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/Kirsten/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import relevant tools for NLP and load the english language library\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant tools to get text from a website\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location of website and getting the content with BeautifulSoup\n",
    "#url = \"https://hbr.org/2020/01/the-upside-of-being-an-underdog\"\n",
    "url=\"https://hbr.org/2020/01/making-stakeholder-capitalism-a-reality\"\n",
    "webpage = requests.get(url)\n",
    "content_page = webpage.content\n",
    "soup = BeautifulSoup(content_page, 'html.parser')\n",
    "title = []\n",
    "paragraphtext = []    \n",
    " \n",
    "# get article title\n",
    "try:\n",
    "    abody = soup.find('title')\n",
    "    title = abody.get_text() \n",
    "except:\n",
    "    title = 'Anonymous'\n",
    "## get main article text\n",
    "articlebody = soup.find(class_='article article-first-row').find_all('p')\n",
    "#put main body of text into a list with the text structured paragraph by paragraph\n",
    "for paragraph in articlebody[:]:\n",
    "        # get the text only\n",
    "    text = paragraph.get_text()\n",
    "    paragraphtext.append(text)        \n",
    "    \n",
    "#print(title)\n",
    "#print(paragraphtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = nlp(paragraphtext[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FREQcount</th>\n",
       "      <th>CDcount</th>\n",
       "      <th>FREQlow</th>\n",
       "      <th>Cdlow</th>\n",
       "      <th>SUBTLWF</th>\n",
       "      <th>Lg10WF</th>\n",
       "      <th>SUBTLCD</th>\n",
       "      <th>Lg10CD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1501908</td>\n",
       "      <td>8388</td>\n",
       "      <td>1339811</td>\n",
       "      <td>8388</td>\n",
       "      <td>29449.18</td>\n",
       "      <td>6.1766</td>\n",
       "      <td>100.00</td>\n",
       "      <td>3.9237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>1156570</td>\n",
       "      <td>8383</td>\n",
       "      <td>1138435</td>\n",
       "      <td>8380</td>\n",
       "      <td>22677.84</td>\n",
       "      <td>6.0632</td>\n",
       "      <td>99.94</td>\n",
       "      <td>3.9235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1041179</td>\n",
       "      <td>8382</td>\n",
       "      <td>976941</td>\n",
       "      <td>8380</td>\n",
       "      <td>20415.27</td>\n",
       "      <td>6.0175</td>\n",
       "      <td>99.93</td>\n",
       "      <td>3.9234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>2134713</td>\n",
       "      <td>8381</td>\n",
       "      <td>1595028</td>\n",
       "      <td>8376</td>\n",
       "      <td>41857.12</td>\n",
       "      <td>6.3293</td>\n",
       "      <td>99.92</td>\n",
       "      <td>3.9233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>682780</td>\n",
       "      <td>8379</td>\n",
       "      <td>515365</td>\n",
       "      <td>8374</td>\n",
       "      <td>13387.84</td>\n",
       "      <td>5.8343</td>\n",
       "      <td>99.89</td>\n",
       "      <td>3.9232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FREQcount  CDcount  FREQlow  Cdlow   SUBTLWF  Lg10WF  SUBTLCD  Lg10CD\n",
       "Word                                                                       \n",
       "the     1501908     8388  1339811   8388  29449.18  6.1766   100.00  3.9237\n",
       "to      1156570     8383  1138435   8380  22677.84  6.0632    99.94  3.9235\n",
       "a       1041179     8382   976941   8380  20415.27  6.0175    99.93  3.9234\n",
       "you     2134713     8381  1595028   8376  41857.12  6.3293    99.92  3.9233\n",
       "and      682780     8379   515365   8374  13387.84  5.8343    99.89  3.9232"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in subtlexus corpus, large corpus with frequency information\n",
    "corpus = pd.read_csv('SUBTLEXusExcel2007.tsv', sep='\\t',index_col =\"Word\")\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wickedly critical reality\n"
     ]
    }
   ],
   "source": [
    "#for those word types carrying meaning, make a ranking according to frequency\n",
    "listofwordtypes=['VERB','ADV','NOUN','ADJ']\n",
    "counter=0\n",
    "corpus_results=[]\n",
    "corpus_results_counter=[]\n",
    "for token in input_text: \n",
    "    if (token.pos_ in listofwordtypes):\n",
    "        try:\n",
    "            corpus_results.append(corpus.loc[token.lemma_,'Lg10WF'])\n",
    "            corpus_results_counter.append(counter)\n",
    "        except KeyError:\n",
    "              pass\n",
    "        #  print('x')\n",
    "        # print('x')\n",
    "    #  #  print(corpus.loc[token.lemma_,'Lg10WF'])#,corpus.loc[token.lemma_].Lg10WF)\n",
    "    counter=counter+1 \n",
    "outputtuple=sorted(zip(corpus_results, corpus_results_counter))[:3]    \n",
    "print(input_text[outputtuple[0][1]],input_text[outputtuple[1][1]],input_text[outputtuple[2][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['evilly', 'vital', 'decisive', 'world', 'realness', 'realism']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn  #Import wordnet from the NLTK\n",
    "syn=[]\n",
    "for thing in outputtuple:\n",
    "    for synset in wn.synsets(str(input_text[thing[1]])):\n",
    "        for lemma in synset.lemmas():\n",
    "            #print((input_text[thing[1]]))\n",
    "            #print(lemma.name())\n",
    "            if str(lemma.name()) != str(input_text[thing[1]]):\n",
    "                syn.append(lemma.name())    #add the synonyms\n",
    "\n",
    "print(syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tools for putting information into a database\n",
    "import sqlite3\n",
    "from sqlite3 import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    " \n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_TextFromWebsites_table(conn, website):\n",
    "    \"\"\"\n",
    "    Create a new project into the projects table\n",
    "    :param conn:\n",
    "    :param project:\n",
    "    :return: project id\n",
    "    \"\"\"\n",
    "    sql = ''' INSERT INTO websitetext(name,url,nopara,para1,para2,para3,para4)\n",
    "              VALUES(?,?,?,?,?,?,?) '''\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql, website)\n",
    "    return cur.lastrowid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    database = r\"/Users/Kirsten/InsightProjectLocalStuff/Ideas/MVP/Database/insightproject.db\"\n",
    "  # create a database connection\n",
    "    conn = create_connection(database)\n",
    "    with conn:\n",
    "        website_2=(title,url,len(paragraphtext),paragraphtext[0],paragraphtext[1],paragraphtext[2],paragraphtext[3])\n",
    "        create_TextFromWebsites_table(conn,website_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragraphtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
